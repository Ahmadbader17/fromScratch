{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 What is XGBoost?\n",
    "\n",
    "XGBoost stands for eXtreme Gradient Boosting. It is a powerful and efficient implementation of gradient boosting, which is a machine learning technique for regression, classification, and ranking problems. XGBoost is widely used in competitions like Kaggle due to its speed and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Key Terms\n",
    "\n",
    "1. Decision Trees: A tree-like model of decisions used for classification or regression.\n",
    "\n",
    "2. Gradient Boosting: A technique where new models are added to correct the errors made by existing models. Models are added sequentially until no further improvements can be made.\n",
    "\n",
    "3. Loss Function: A function that measures the difference between the predicted value and the actual value.\n",
    "\n",
    "4. Regularization: A technique to prevent overfitting by adding a penalty for complexity to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Basic Idea of XGBoost\n",
    "\n",
    "XGBoost builds an ensemble of decision trees sequentially. Each new tree tries to correct the mistakes of the previous trees. The key innovation in XGBoost is the use of gradient descent to minimize the loss function, and it uses first and second-order gradients to do this efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Boosting vs. Other Ensemble Methods\n",
    "\n",
    "![Difference](images/boost.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Types of Boosting Algorithms\n",
    "\n",
    "    ✅ AdaBoost (Adaptive Boosting) – Adjusts sample weights.\n",
    "    ✅ Gradient Boosting (GBM) – Uses gradient descent.\n",
    "    ✅ XGBoost (eXtreme Gradient Boosting) – Optimized gradient boosting with regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Code Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature_index = feature_index  # Index of the feature to split on\n",
    "        self.threshold = threshold          # Threshold value for the split\n",
    "        self.left = left                  # Left subtree\n",
    "        self.right = right                # Right subtree\n",
    "        self.value = value                # Value if the node is a leaf\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=3, min_samples_split=2, gamma=0, lambda_=1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.gamma = gamma\n",
    "        self.lambda_=lambda_\n",
    "        self.root = None\n",
    "\n",
    "    def _calculate_gain(self, g_L, h_L, g_R, h_R, g, h):\n",
    "        gain = 0.5 * ((g_L**2 / (h_L + self.lambda_)) + (g_R**2 / (h_R + self.lambda_)) - (g**2 / (h + self.lambda_))) - self.gamma\n",
    "        return gain\n",
    "\n",
    "    def _split(self, X, g, h):\n",
    "        best_gain = -np.inf \n",
    "        best_feature_index = None \n",
    "        best_threshold = None\n",
    "\n",
    "        for feature_index in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = X[:, feature_index] <= threshold\n",
    "                right_indices = X[:, feature_index] > threshold \n",
    "\n",
    "                g_L, h_L = g[left_indices].sum(), h[left_indices].sum()\n",
    "                g_R, h_R = g[right_indices].sum(), h[right_indices].sum()\n",
    "\n",
    "                gain = self._calculate_gain(g_L, h_L, g_R, g_L, g.sum(), h.sum())\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain \n",
    "                    best_feature_index = feature_index\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature_index, best_threshold\n",
    "    \n",
    "    def _build_tree(self, X, g, h, depth=0):\n",
    "        num_samples, num_features = X.shape \n",
    "        if depth >= self.max_depth or num_samples < self.min_samples_split:\n",
    "            leaf_value = -g.sum() / (h.sum() + self.lambda_) \n",
    "            return TreeNode(value=leaf_value)\n",
    "        \n",
    "        feature_index, threshold = self._split(X, g, h)\n",
    "\n",
    "        if feature_index is None:\n",
    "            leaf_value = -g.sum() / (h.sum() + self.lambda_)\n",
    "            return TreeNode(value=leaf_value)\n",
    "        \n",
    "        left_indices = X[:, feature_index] <= threshold\n",
    "        right_indices = X[:, feature_index] > threshold\n",
    "\n",
    "        left = self._build_tree(X[left_indices], g[left_indices], h[left_indices], depth + 1)\n",
    "        right = self._build_tree(X[right_indices], g[right_indices], h[right_indices], depth + 1)\n",
    "\n",
    "        return TreeNode(feature_index, threshold, left, right)\n",
    "    \n",
    "\n",
    "    def fit(self, X, g, h):\n",
    "        self.root = self._build_tree(X, g, h)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_tree(x, self.root) for x in X])\\\n",
    "        \n",
    "    def _predict_tree(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value \n",
    "        if x[node.feature_index] <= node.threshold:\n",
    "            return self._predict_tree(x, node.left)\n",
    "        else:\n",
    "            return self._predict_tree(x, node.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoost:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3, min_samples_split=2, gamma=0, lambda_=1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.gamma = gamma\n",
    "        self.lambda_ = lambda_\n",
    "        self.trees = []\n",
    "\n",
    "    def _gradient(self, y, y_pred):\n",
    "        return y_pred - y\n",
    "\n",
    "    def _hessian(self, y, y_pred):\n",
    "        return np.ones_like(y)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y_pred = np.full_like(y, np.mean(y), dtype=np.float64)  # Initialize as float array\n",
    "        for _ in range(self.n_estimators):\n",
    "            g = self._gradient(y, y_pred)\n",
    "            h = self._hessian(y, y_pred)\n",
    "\n",
    "            tree = DecisionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split, gamma=self.gamma, lambda_=self.lambda_)\n",
    "            tree.fit(X, g, h)\n",
    "\n",
    "            self.trees.append(tree)\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(X.shape[0], dtype=np.float64)  # Initialize as float array\n",
    "        for tree in self.trees:\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.52848098e+01 -3.58280882e+01  3.13122564e+01  1.19586570e+01\n",
      " -2.65633422e+01 -3.31923004e+01 -3.58280882e+01 -1.79788958e+01\n",
      " -2.73454926e+00  3.11767501e+01 -3.40359032e+01 -2.94007354e+01\n",
      " -2.53944248e+01  2.19191434e+01 -2.84268139e+01  1.64361648e+01\n",
      "  3.82321580e+01  3.04582263e+01 -1.50023391e+01 -1.27356992e+01\n",
      " -2.53944248e+01 -3.58280882e+01 -2.29378359e+01  3.82321580e+01\n",
      "  1.79977429e+00  1.21426407e+01 -1.07338266e+01 -2.73454926e+00\n",
      " -3.88073219e+00  2.48433948e+01  1.26840581e+00 -3.58280882e+01\n",
      "  4.04418986e+01 -3.10001337e+01 -3.58280882e+01 -4.17265612e+00\n",
      "  3.34055746e+01  1.93998633e+01  3.82321580e+01  1.93998633e+01\n",
      "  1.34888165e+01 -3.40359032e+01 -1.15215217e+01 -3.58280882e+01\n",
      "  3.82321580e+01 -2.53944248e+01 -7.44044044e+00 -2.72578964e+01\n",
      " -3.58280882e+01  2.94330213e+01 -3.23636039e+00  2.17775676e+01\n",
      " -1.17055054e+01 -2.34618744e+01 -6.49246457e+00 -3.58280882e+01\n",
      "  3.11767501e+01 -3.58280882e+01 -9.23251519e+00  4.06995092e+00\n",
      " -3.75516258e+01  2.03889838e+01 -3.32372302e+01 -2.72578964e+01\n",
      " -2.53944248e+01  1.00784362e+01  1.84829088e+00 -1.70007642e+01\n",
      " -2.53944248e+01 -3.58280882e+01 -3.58280882e+01  3.04582263e+01\n",
      "  1.69602032e+01 -1.33146213e+01  1.89717951e+01 -4.17265612e+00\n",
      "  1.17810059e+01 -2.97189414e+01  7.39676543e+00 -2.97189414e+01\n",
      "  3.04582263e+01 -2.17082818e+01 -3.58280882e+01 -7.56113272e+00\n",
      " -3.58280882e+01 -1.04650179e+01 -3.00035866e+01  2.09327565e+01\n",
      " -3.58280882e+01 -2.53944248e+01 -3.58280882e+01  2.71737950e+01\n",
      "  2.44970435e+01 -3.58280882e+01 -2.74344277e+01  1.24067532e+00\n",
      "  3.34055746e+01  2.82294018e+01 -5.38624245e+00 -1.72797837e+01\n",
      "  2.63501667e+01 -2.53944248e+01  1.15858351e+01  1.40630411e+01\n",
      " -2.05786534e+01 -2.53944248e+01 -2.97189414e+01 -2.32900549e+01\n",
      "  3.82321580e+01 -1.15215217e+01 -2.08636727e+01 -9.51936046e+00\n",
      " -3.55817765e+00  3.34055746e+01  3.82321580e+01  1.79465901e+01\n",
      "  3.52848098e+01  2.38039628e+01  1.34888165e+01 -1.19516242e+01\n",
      " -1.24536474e+01  3.04582263e+01  3.82321580e+01  3.13122564e+01\n",
      "  9.23645766e+00  1.24636115e+01 -3.58280882e+01  1.31357701e+01\n",
      " -2.72578964e+01  2.94330213e+01  3.52848098e+01 -2.97189414e+01\n",
      " -1.70007642e+01 -3.58280882e+01  1.26840581e+00  3.11767501e+01\n",
      " -3.31923004e+01  3.52848098e+01  3.52848098e+01  3.82321580e+01\n",
      " -6.49246457e+00  2.71737950e+01  3.34055746e+01 -1.64262007e+01\n",
      "  3.13122564e+01  1.40630411e+01  3.13122564e+01  2.82294018e+01\n",
      " -3.55817765e+00  1.24000363e+01  1.40630411e+01 -3.52277078e+00\n",
      "  1.89717951e+01 -3.58280882e+01  2.64856730e+01  3.82321580e+01\n",
      " -1.17055054e+01 -7.04425942e+00 -2.53944248e+01  3.82321580e+01\n",
      " -3.58280882e+01  3.82321580e+01 -7.56113272e+00  1.40630411e+01\n",
      "  8.19355773e+00 -3.58280882e+01 -3.58280882e+01  3.82321580e+01\n",
      "  3.42596047e+01  1.72622505e+01 -3.07312613e+01 -3.58280882e+01\n",
      "  3.82321580e+01 -2.72578964e+01  2.19444116e+01 -2.53944248e+01\n",
      "  2.17775676e+01  2.63501667e+01 -3.07312613e+01  1.15888024e+01\n",
      "  2.44970435e+01 -2.72578964e+01  2.44970435e+01 -7.04425942e+00\n",
      "  2.63501667e+01  1.66201485e+01  3.11767501e+01 -3.58280882e+01\n",
      "  9.30474954e+00 -2.53944248e+01  2.08566145e+01 -6.85578668e+00\n",
      " -2.72578964e+01  1.24000363e+01 -1.19516242e+01  3.04582263e+01\n",
      " -3.58280882e+01  2.44970435e+01 -2.37479724e+01 -9.02790002e+00\n",
      " -2.53944248e+01 -3.58280882e+01  2.19191434e+01  3.04582263e+01\n",
      "  2.44970435e+01  3.82321580e+01  2.64856730e+01  3.82321580e+01\n",
      "  2.66041510e+01 -1.28442272e+01 -6.49246457e+00  1.40630411e+01\n",
      "  1.58163848e+01 -2.53944248e+01 -3.58280882e+01  3.82321580e+01\n",
      "  3.82321580e+01  3.34055746e+01  3.86303783e+00 -6.85578668e+00\n",
      " -2.96705899e+01 -1.19516242e+01 -4.17265612e+00 -1.92852779e+01\n",
      " -3.58280882e+01  3.34055746e+01 -2.97189414e+01 -3.58280882e+01\n",
      " -1.50023391e+01 -2.02975978e+01  2.71737950e+01 -4.17265612e+00\n",
      "  1.49992418e+01 -2.73454926e+00  3.82321580e+01 -9.15808428e+00\n",
      "  2.74443918e+01 -3.58280882e+01  1.36728002e+01  2.94330213e+01\n",
      "  3.82321580e+01 -1.17055054e+01 -3.40359032e+01 -3.58280882e+01\n",
      " -1.92870999e+01 -3.58280882e+01  2.20647924e+00 -2.72578964e+01\n",
      "  3.82321580e+01  3.82321580e+01  3.82321580e+01  3.82321580e+01\n",
      "  6.69082105e+00  3.34055746e+01  3.82321580e+01 -1.43283527e+01\n",
      "  2.42264468e+01 -2.17082818e+01 -3.62039905e+01 -3.58280882e+01\n",
      " -3.50456568e+01 -2.53944248e+01  3.82321580e+01 -3.58280882e+01\n",
      " -2.37479724e+01 -4.17265612e+00 -3.58280882e+01  1.74416356e+01\n",
      "  3.52848098e+01 -2.53944248e+01  3.04582263e+01  3.27527485e+00\n",
      " -4.16140851e+00  1.64361648e+01 -4.17265612e+00  1.34888165e+01\n",
      "  3.34055746e+01 -3.10001337e+01 -1.03577413e+00 -2.53944248e+01\n",
      "  3.04582263e+01 -2.00447813e+01 -3.52277078e+00 -3.58280882e+01\n",
      " -2.76425121e-02  1.98314095e+01 -3.10001337e+01  1.69602032e+01\n",
      " -2.34618744e+01  2.71737950e+01  3.52848098e+01  3.87635265e+01\n",
      " -3.58280882e+01 -6.49246457e+00 -3.58280882e+01  2.42264468e+01\n",
      " -3.58280882e+01 -3.07312613e+01 -2.53944248e+01 -1.70007642e+01\n",
      "  2.71737950e+01 -2.53944248e+01  3.04582263e+01  3.82321580e+01\n",
      " -1.95699232e+01 -1.41909982e+01 -1.79788958e+01 -4.17265612e+00\n",
      " -3.58280882e+01  1.49992418e+01  1.40630411e+01  2.42264468e+01\n",
      " -3.58280882e+01  3.82321580e+01  1.00904878e+01 -2.02975978e+01\n",
      "  2.94330213e+01 -7.04425942e+00  2.44970435e+01  2.44970435e+01\n",
      "  2.94330213e+01  3.82321580e+01  3.82321580e+01  2.09327565e+01\n",
      "  2.74443918e+01  2.71737950e+01  1.19586570e+01  2.66041510e+01\n",
      "  1.55457881e+01 -2.53944248e+01  9.23645766e+00 -3.00035866e+01\n",
      "  3.82321580e+01  1.79854082e+01 -3.58280882e+01 -3.58280882e+01\n",
      "  3.11767501e+01  1.34888165e+01 -2.72578964e+01  1.24000363e+01\n",
      " -2.34618744e+01  1.40630411e+01  9.23645766e+00 -6.49246457e+00\n",
      "  1.08035467e+01  7.77459000e+00  3.34055746e+01 -4.17265612e+00\n",
      " -1.70007642e+01 -3.62039905e+01  3.82321580e+01 -3.58280882e+01\n",
      " -3.10001337e+01 -9.02790002e+00  3.82321580e+01 -2.34618744e+01\n",
      " -2.72578964e+01  3.87635265e+01 -3.58280882e+01  2.44970435e+01\n",
      "  3.04582263e+01 -1.75991926e+01  3.52848098e+01 -4.54855844e+00\n",
      "  1.64552487e+01 -1.19516242e+01  3.42596047e+01  3.82321580e+01\n",
      "  2.19191434e+01  6.69082105e+00 -3.58280882e+01  1.64361648e+01\n",
      " -2.53944248e+01 -2.74344277e+01 -7.22629053e+00  1.79854082e+01\n",
      "  3.42596047e+01  3.58161782e+01  1.49992418e+01 -3.58280882e+01\n",
      " -6.49246457e+00 -2.58011658e+01  3.11767501e+01 -2.53944248e+01\n",
      " -4.17265612e+00 -1.30282109e+01 -2.53944248e+01 -1.07481514e+01\n",
      " -4.17265612e+00 -2.52482827e+01  3.82321580e+01 -3.58280882e+01\n",
      " -3.58280882e+01 -3.58280882e+01  3.34055746e+01  2.27995875e+01\n",
      " -3.58280882e+01  1.94025970e+01  3.17081186e+01  3.34055746e+01\n",
      " -6.49246457e+00 -3.58280882e+01 -1.03577413e+00  3.42596047e+01\n",
      "  1.40630411e+01  4.07767063e+01 -3.58280882e+01 -2.32900549e+01\n",
      " -9.02790002e+00  1.34888165e+01  4.06995092e+00 -2.76044505e+01\n",
      "  3.52848098e+01 -2.52482827e+01  2.34718385e+01  1.74416356e+01\n",
      "  1.40630411e+01 -2.32900549e+01 -2.53944248e+01 -3.58280882e+01\n",
      " -2.26357887e+01  3.34055746e+01  3.82321580e+01 -1.23275266e+01\n",
      "  2.34028184e+01 -2.28498765e+01 -4.12053520e+00 -1.64262007e+01\n",
      "  3.82321580e+01 -2.53944248e+01 -2.53944248e+01 -2.53944248e+01\n",
      "  3.42596047e+01 -3.58280882e+01 -1.79788958e+01 -3.58280882e+01\n",
      " -3.58280882e+01  3.04582263e+01 -2.02975978e+01 -2.34618744e+01\n",
      "  3.42596047e+01 -2.17082818e+01]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the Diabetes dataset\n",
    "data = load_diabetes()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost model\n",
    "model = XGBoost(n_estimators=10, learning_rate=0.1, max_depth=3)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
