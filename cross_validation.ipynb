{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation:\n",
    "\n",
    "Cross-validation is a statistical method used to evaluate the performance of machine learning models. It helps in assessing how the results of a model will generalize to an independent dataset. The main goal is to prevent overfitting, which occurs when a model learns the training data too well, capturing noise and outliers, and performs poorly on unseen data.\n",
    "\n",
    "#### Types of Cross-Validation:\n",
    "\n",
    "1) K-Fold Cross-Validation: The dataset is divided into k subsets (or folds). The model is trained on k-1 folds and validated on the remaining fold. This process is repeated k times, each time with a different fold as the validation set. The final performance metric is the average of the k validation scores.\n",
    "\n",
    "2) Stratified K-Fold Cross-Validation: Similar to K-Fold, but it ensures that each fold has the same proportion of observations with a given label. This is particularly useful for imbalanced datasets.\n",
    "\n",
    "3) Leave-One-Out Cross-Validation (LOOCV): A special case of K-Fold where k equals the number of data points. Each iteration uses one data point as the validation set and the rest as the training set.\n",
    "\n",
    "4) Time Series Cross-Validation: Used for time series data, where the training set consists of past observations and the validation set consists of future observations.\n",
    "\n",
    "\n",
    "##### Why Use Cross-Validation?\n",
    "\n",
    "1) Model Evaluation: It provides a more accurate estimate of the model's performance on unseen data.\n",
    "\n",
    "2) Hyperparameter Tuning: Helps in selecting the best hyperparameters by evaluating the model on multiple subsets of the data.\n",
    "\n",
    "3) Preventing Overfitting: Ensures that the model generalizes well to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\lenovo\\miniconda3\\envs\\fs\\lib\\site-packages (from scikit-learn) (2.2.1)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.1-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.6.1-cp313-cp313-win_amd64.whl (11.1 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached scipy-1.15.1-cp313-cp313-win_amd64.whl (43.6 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.model_selection import KFold, cross_val_score \n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize random forest classfier\n",
    "model = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize K-Fold cross-validation\n",
    "k_folds = 5\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for each fold: [1.         0.96666667 0.93333333 0.93333333 0.96666667]\n",
      "Mean accuracy: 0.9600\n",
      "Standard deviation of accuracy: 0.0249\n"
     ]
    }
   ],
   "source": [
    "# Output the results\n",
    "print(f\"Accuracy scores for each fold: {scores}\")\n",
    "print(f\"Mean accuracy: {np.mean(scores):.4f}\")\n",
    "print(f\"Standard deviation of accuracy: {np.std(scores):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
