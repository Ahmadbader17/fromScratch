{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "What is Gini Impurity?\n",
    "Gini Impurity is a measure of how often a randomly chosen element from a set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset. It ranges from 0 to 0.5:\n",
    "\n",
    "0: The set is perfectly pure (all elements belong to the same class).\n",
    "\n",
    "0.5: The set is maximally impure (elements are evenly distributed across classes).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeNode:\n",
    "    def __init__ (self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
    "        \"\"\"\n",
    "         A node in the decision tree.\n",
    "        - feature_index: Index of the feature used for splitting.\n",
    "        - threshold: Threshold value for the split.\n",
    "        - left: Left child node (samples <= threshold).\n",
    "        - right: Right child node (samples > threshold).\n",
    "        - value: Predicted value if the node is a leaf.\n",
    "        \"\"\"\n",
    "\n",
    "        self.feature_index=feature_index\n",
    "        self.threshold=threshold\n",
    "        self.left=left \n",
    "        self.right=right\n",
    "        self.value=value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        \"\"\" \n",
    "        Decision Tree Classifier.\n",
    "        - max_depth: Maximum depth of the tree.        \n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" \n",
    "        Build the decision tree.\n",
    "        - X: Feature matrix (n_samples, n_features).\n",
    "        - y: Target vector (n_samples,).        \n",
    "        \"\"\"\n",
    "        self.root=self._grow_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" \n",
    "        Predict the target for input data.\n",
    "        - X: Feature matrix (n_samples, n_features).        \n",
    "        \"\"\"\n",
    "        return np.array([self._predict(inputs) for inputs in X])\n",
    "    \n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        \"\"\" \n",
    "        Recursively grow the decision tree.\n",
    "        - X: Feature matrix.\n",
    "        - y: Target vector.\n",
    "        - depth: Current depth of the tree.        \n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        # Stopping conditions:\n",
    "        # 1. All samples have the same label.\n",
    "        # 2. Maximum depth is reached.\n",
    "        # 3. No features left to split on.\n",
    "        if n_labels==1 or depth==self.max_depth or n_samples < 2:\n",
    "            left_value = self._most_common_label(y)\n",
    "            return DecisionTreeNode(value=left_value)\n",
    "        \n",
    "        # Find the best split\n",
    "        feature_index, threshold = self._best_split(X, y)\n",
    "\n",
    "        # Split the data\n",
    "        left_indices = X[:, feature_index] <= threshold \n",
    "        right_indices = X[:, feature_index] > threshold\n",
    "        X_left, y_left = X[left_indices], y[left_indices] \n",
    "        X_right, y_right = X[right_indices], y[right_indices]\n",
    "\n",
    "        # Recursively grow the left and right subtree\n",
    "        left_child = self._grow_tree(X_left, y_left, depth + 1)\n",
    "        right_child = self._grow_tree(X_right, y_right, depth + 1)\n",
    "\n",
    "        return DecisionTreeNode(feature_index, threshold, left_child, right_child)\n",
    "    \n",
    "    def _best_split(self, X, y):\n",
    "        \"\"\"\n",
    "        Find the best feature and threshold to split the data.\n",
    "        - X: Feature matrix.\n",
    "        - y: Target vector.\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        best_gini = float('inf')\n",
    "        best_feature_index, best_threshold = None, None\n",
    "\n",
    "        # Iterate over all features and thresholds to find the best split \n",
    "        for feature_index in range(n_features):\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = X[:, feature_index] <= threshold\n",
    "                right_indices = X[:, feature_index] > threshold \n",
    "                if sum(left_indices) == 0 or sum(right_indices) == 0:\n",
    "                    continue \n",
    "\n",
    "                #calculate gini impurity for the split \n",
    "                gini = self._gini(y[left_indices]) * sum(left_indices)/n_samples + \\\n",
    "                    self._gini(y[right_indices]) * sum(right_indices)/n_samples \n",
    "\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_feature_index = feature_index\n",
    "                    best_threshold=threshold\n",
    "\n",
    "        return best_feature_index, best_threshold\n",
    "\n",
    "    def _gini(self, y):\n",
    "        \"\"\" \n",
    "        Calculate the gini impurity for a set of labels.\n",
    "        - y : Target vector\n",
    "        \"\"\"      \n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        return 1 - np.sum(probabilities ** 2)\n",
    "    \n",
    "    def _most_common_label(self, y):\n",
    "        \"\"\" \n",
    "        Return the most common label in a set.\n",
    "        - y : Target vector\n",
    "        \"\"\"\n",
    "\n",
    "        return np.bincount(y).argmax()\n",
    "    \n",
    "    def _predict(self, inputs):\n",
    "        \"\"\" \n",
    "        Predicts the target for a single input by traversing the tree. \n",
    "        - inputs: A single sample's features\n",
    "        \"\"\"\n",
    "\n",
    "        node = self.root \n",
    "        while node.value is None:\n",
    "            if inputs[node.feature_index] <= node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right \n",
    "        return node.value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample dataset\n",
    "    X = np.array([[2, 3], [10, 15], [3, 4], [6, 8], [7, 10], [8, 12]])\n",
    "    y = np.array([0, 1, 0, 1, 1, 1])\n",
    "\n",
    "    # Train the decision tree\n",
    "    tree = DecisionTree(max_depth=3)\n",
    "    tree.fit(X, y)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = tree.predict(X)\n",
    "    print(\"Predictions:\", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
