{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression (L2 Regularization):\n",
    "\n",
    "## 1. Pseudo Code for Ridge Regression\n",
    "Initialize weights (coefficients) and bias (intercept) to small random values or zeros.\n",
    "\n",
    "Define the regularization parameter alpha (controls the strength of regularization).\n",
    "\n",
    "For each iteration:\n",
    "\n",
    "Compute the predicted values using the current weights and bias.\n",
    "\n",
    "Compute the loss function:\n",
    "\n",
    "Mean Squared Error (MSE) + L2 penalty term (alpha * sum of squared weights).\n",
    "\n",
    "Compute gradients for weights and bias:\n",
    "\n",
    "Gradient for weights = (-2/n) * X.T @ (y_true - y_pred) + 2 * alpha * weights\n",
    "\n",
    "Gradient for bias = (-2/n) * sum(y_true - y_pred)\n",
    "\n",
    "Update weights and bias using gradient descent:\n",
    "\n",
    "weights = weights - learning_rate * gradient_weights\n",
    "\n",
    "bias = bias - learning_rate * gradient_bias\n",
    "\n",
    "Repeat until convergence or a fixed number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RidgeRegression:\n",
    "    def __init__(self, alpha=0.5, learning_rate=0.01, n_iterations=1000):\n",
    "        self.alpha = alpha  # Regularization strength\n",
    "        self.learning_rate = learning_rate  # Step size for gradient descent\n",
    "        self.n_iterations = n_iterations  # Number of iterations\n",
    "        self.weights = None  # Coefficients\n",
    "        self.bias = None  # Intercept\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Initialize weights and bias\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        # Gradient Descent\n",
    "        for _ in range(self.n_iterations):\n",
    "            # Predictions\n",
    "            y_pred = np.dot(X, self.weights) + self.bias\n",
    "\n",
    "            # Compute gradients\n",
    "            dw = (-2 / n_samples) * np.dot(X.T, (y - y_pred)) + (2 * self.alpha * self.weights)\n",
    "            db = (-2 / n_samples) * np.sum(y - y_pred)\n",
    "\n",
    "            # Update weights and bias\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [2.39273504 3.1244226  3.85611016 4.58779772]\n"
     ]
    }
   ],
   "source": [
    "# Example dataset\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "y = np.array([2, 3, 4, 5])\n",
    "\n",
    "# Create and train Ridge Regression model\n",
    "model = RidgeRegression(alpha=1.0, learning_rate=0.01, n_iterations=1000)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X)\n",
    "print(\"Predictions:\", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
