{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest: An Overview\n",
    "\n",
    "Random Forest is an **ensemble learning algorithm** that builds multiple **decision trees** and aggregates their predictions to improve accuracy and reduce overfitting. It operates using two key concepts:\n",
    "\n",
    "1. **Bootstrap Sampling** – Each tree is trained on a randomly selected subset of the training data with replacement.\n",
    "2. **Feature Randomness** – At each split, only a random subset of features is considered, increasing diversity among trees.\n",
    "\n",
    "During **prediction**, the final output is determined by **majority voting** (for classification) or **averaging** (for regression). Random Forest is widely used due to its **robustness, scalability, and ability to handle both numerical and categorical data**. Additionally, it provides insights into **feature importance**, making it useful for interpretability. However, training a large number of trees can be computationally expensive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, data, features):\n",
    "        self.tree = self._build_tree(data, features)\n",
    "\n",
    "    def _build_tree(self, data, features, depth=0):\n",
    "        if len(data) < self.min_samples_split or (self.max_depth is not None and depth >= self.max_depth):\n",
    "            return Counter(data.iloc[:, -1])\n",
    "        feature, threshold = self._best_split(data, features)\n",
    "        if feature is None:\n",
    "            return Counter(data.iloc[:, -1])\n",
    "        left, right = self._split_data(data, feature, threshold)\n",
    "        left_branch = self._build_tree(left, features, depth + 1)\n",
    "        right_branch = self._build_tree(right, features, depth + 1)\n",
    "        return (feature, threshold, left_branch, right_branch)\n",
    "\n",
    "    def _best_split(self, data, features):\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_gini = 1\n",
    "        for feature in features:\n",
    "            thresholds = np.unique(data[feature])\n",
    "            for threshold in thresholds:\n",
    "                left, right = self._split_data(data, feature, threshold)\n",
    "                if len(left) == 0 or len(right) == 0:\n",
    "                    continue\n",
    "                gini = (len(left) * self._gini_impurity(left.iloc[:, -1]) + len(right) * self._gini_impurity(right.iloc[:, -1])) / len(data)\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _split_data(self, data, feature, threshold):\n",
    "        left = data[data[feature] <= threshold]\n",
    "        right = data[data[feature] > threshold]\n",
    "        return left, right\n",
    "\n",
    "    def _gini_impurity(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / counts.sum()\n",
    "        return 1 - np.sum(probabilities ** 2)\n",
    "\n",
    "    def predict(self, sample):\n",
    "        return self._predict_tree(self.tree, sample)\n",
    "\n",
    "    def _predict_tree(self, tree, sample):\n",
    "        if isinstance(tree, Counter):\n",
    "            return tree.most_common(1)[0][0]\n",
    "        feature, threshold, left, right = tree\n",
    "        if sample[feature] <= threshold:\n",
    "            return self._predict_tree(left, sample)\n",
    "        else:\n",
    "            return self._predict_tree(right, sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_trees=10, max_depth=None, min_samples_split=2, max_features=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_features = max_features\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, data):\n",
    "        for _ in range(self.n_trees):\n",
    "            bootstrap = self._bootstrap_sample(data)\n",
    "            features = np.random.choice(data.columns[:-1], size=self.max_features, replace=False)\n",
    "            tree = DecisionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "            tree.fit(bootstrap, features)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def _bootstrap_sample(self, data):\n",
    "        indices = np.random.choice(len(data), size=len(data), replace=True)\n",
    "        return data.iloc[indices]\n",
    "\n",
    "    def predict(self, sample):\n",
    "        predictions = [tree.predict(sample) for tree in self.trees]\n",
    "        return Counter(predictions).most_common(1)[0][0]\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        predictions = [self.predict(test_data.iloc[i]) for i in range(len(test_data))]\n",
    "        accuracy = np.mean(predictions == test_data.iloc[:, -1])\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_iris_dataset():\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "    column_names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"]\n",
    "    data = pd.read_csv(url, header=None, names=column_names)\n",
    "    return data\n",
    "\n",
    "def train_test_split(data, test_size=0.2, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    shuffled = data.sample(frac=1, random_state=seed)\n",
    "    test_size = int(len(shuffled) * test_size)\n",
    "    test_data = shuffled.iloc[:test_size]\n",
    "    train_data = shuffled.iloc[test_size:]\n",
    "    return train_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    data = load_iris_dataset()\n",
    "    train_data, test_data = train_test_split(data)\n",
    "    forest = RandomForest(n_trees=10, max_depth=5, max_features=2)\n",
    "    forest.fit(train_data)\n",
    "    accuracy = forest.evaluate(test_data)\n",
    "    print(f\"Random Forest Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
